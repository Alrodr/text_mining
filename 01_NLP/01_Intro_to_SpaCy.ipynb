{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "\n",
    "\n",
    "# Load spacy resources\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process text\n",
    "doc = en_nlp(u'Dive into NLTK: Part-of-speech tagging and POS Tagger')\n",
    "\n",
    "# Access to the tokens\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to the sentences\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each token, print corresponding part of speech tag\n",
    "for token in doc:\n",
    "    print(token, ' --> ',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several annotations available\n",
    "\n",
    "en_doc = en_nlp(u'They told us to 10 duck.')\n",
    "token_list = []\n",
    "for token in en_doc:\n",
    "    token_list += [(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)]\n",
    "\n",
    "pd.DataFrame(token_list, columns=['text', 'lemma', 'pos', 'tag', 'dep',\n",
    "          'shape', 'is_alpha', 'is_stop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing tree visualization\n",
    "\n",
    "Spacy perform a parsing analysis to obtaing the tree structure od the prhases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = en_nlp(u'This is a sentence.')\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun_chunks:  noun plus the words describing the noun\n",
    "doc = en_nlp(u'Autonomous cars shift insurance liability toward manufacturers')\n",
    "print('Chunk - root - root dep - root head')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, ' -', chunk.root.text, ' -', chunk.root.dep_, ' -', chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example of noun chunks\n",
    "doc_2 = en_nlp(u\"The boy saw the yellow dog\")\n",
    "print([chunk for chunk in doc_2.noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name entities recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name entities\n",
    "doc = en_nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results into the notebook\n",
    "doc = en_nlp(u\"Rami Eid is studying at Stony Brook University in New York\")\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example\n",
    "doc = en_nlp(u\"I went to Paris in 2017 where I met my old friend Jack from uni.\")\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other languages\n",
    "\n",
    "## Available models in: \n",
    "    English (en)\n",
    "    German (de)\n",
    "    Spanish (sp)\n",
    "    Portuguese (pt)\n",
    "    French (fr)\n",
    "    Italian (it)\n",
    "    Dutch (nl)\n",
    "\n",
    "## Languages in alpha version\n",
    "    Swedish (sv)\n",
    "    Finnish (fi)\n",
    "    Norwegian Bokm√•l (nb)\n",
    "    Danish (da)\n",
    "    Hungarian (hu)\n",
    "    Polish(pl)\n",
    "    Russian (ru)\n",
    "    Romanian (ro)\n",
    "    Croatian (hr)\n",
    "    Turkish (tr)\n",
    "    Hebrew (he)\n",
    "    Persian (fa)\n",
    "    Irish (ga)\n",
    "    Bengali (bn)\n",
    "    Hindi (hi)\n",
    "    Indonesian (id)\n",
    "    Thai (th)\n",
    "    Chinese (zh)\n",
    "    Japanese (ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic NLP in spanish\n",
    "es_nlp = spacy.load('es')\n",
    "\n",
    "es_doc = es_nlp(u'Hola Mundo. Aqui tenemos 2 frases.')\n",
    "\n",
    "token_list = []\n",
    "for token in es_doc:\n",
    "    token_list += [(token.text, token.lemma_, token.pos_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)]\n",
    "\n",
    "pd.DataFrame(token_list, columns=['text', 'lemma', 'pos', 'dep',\n",
    "          'shape', 'is_alpha', 'is_stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.lemma_ for t in es_doc if not(t.is_stop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tm]",
   "language": "python",
   "name": "conda-env-tm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
